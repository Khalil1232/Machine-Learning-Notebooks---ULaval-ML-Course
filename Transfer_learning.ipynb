{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khalil1232/Machine-Learning-ULaval/blob/main/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8131ad0c",
      "metadata": {
        "editable": false,
        "id": "8131ad0c",
        "lang": "fr",
        "tags": [
          "problem-title"
        ]
      },
      "source": [
        "# Devoir 4, Question 2 : Transfert de représentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53056292",
      "metadata": {
        "editable": false,
        "id": "53056292",
        "lang": "en"
      },
      "source": [
        "# Homework 4, Question 2: Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65138e1b",
      "metadata": {
        "editable": false,
        "id": "65138e1b",
        "lang": "fr",
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "## Code préambule"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a639ec48",
      "metadata": {
        "editable": false,
        "id": "a639ec48",
        "lang": "en",
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "## Preamble code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d252fa23",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-22T22:47:52.040101Z",
          "start_time": "2022-12-22T22:47:52.021171Z"
        },
        "editable": false,
        "id": "d252fa23",
        "tags": [
          "problem-context",
          "autoexec"
        ]
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "import gzip\n",
        "import time\n",
        "import numpy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet18\n",
        "import torchvision.transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (9.0, 7.0)\n",
        "from matplotlib import pyplot\n",
        "\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def compute_accuracy(model, dataloader, device='cpu'):\n",
        "    training_before = model.training\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    for i_batch, batch in enumerate(dataloader):\n",
        "        images, targets = batch\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "        with torch.no_grad():\n",
        "            predictions = model(images)\n",
        "        all_predictions.append(predictions.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    if all_predictions[0].shape[-1] > 1:\n",
        "        predictions_numpy = numpy.concatenate(all_predictions, axis=0)\n",
        "        predictions_numpy = predictions_numpy.argmax(axis=1)\n",
        "        targets_numpy = numpy.concatenate(all_targets, axis=0)\n",
        "    else:\n",
        "        predictions_numpy = numpy.concatenate(all_predictions).squeeze(-1)\n",
        "        targets_numpy = numpy.concatenate(all_targets)\n",
        "        predictions_numpy[predictions_numpy >= 0.5] = 1.0\n",
        "        predictions_numpy[predictions_numpy < 0.5] = 0.0\n",
        "\n",
        "    if training_before:\n",
        "        model.train()\n",
        "\n",
        "    return (predictions_numpy == targets_numpy).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04390175",
      "metadata": {
        "editable": false,
        "id": "04390175",
        "lang": "fr"
      },
      "source": [
        "Pour cette question, vous devez programmer un cas de transfert de représentation permettant de réutiliser un réseau existant. Un réseau *ResNet-18* préalablement entraîné sur le jeu d'images naturelles *ImageNet* est utilisé comme modèle source. Ce réseau a été préentraîné sur un jeu de données différent, mais de même nature, soit pour de la reconnaissance d'objets. L'adaptation du réseau original pour la nouvelle tâche s'effectue en remplaçant la tête du réseau (couche de sortie) pour que le réseau puisse fonctionner sur le jeu de données [*Lego Brick*](https://www.kaggle.com/joosthazelzet/lego-brick-images), séparé en un ensemble d'[entraînement](https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-train.zip) et de [test](https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-test.zip) (attention: 190 Mo au total, les fichiers sont directement disponibles sur PAX). Vous devriez être en mesure d'atteindre de très bonnes performances sur ce jeu en seulement une époque d'entraînement.\n",
        "\n",
        "En bref, vous devez modifier la dernière couche pleinement connectée du réseau de neurones (couche `fc`) afin de l'adapter au nombre de classes du jeu de données (16 classes ici). De plus, vous devez geler les autres couches du réseau *ResNet-18* se trouvant avant la nouvelle couche pleinement connectée de sortie. Écrivez également la ligne de code nécessaire à l'inférence du réseau dans la méthode `forward`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6fd17ee",
      "metadata": {
        "editable": false,
        "id": "f6fd17ee",
        "lang": "en",
        "lines_to_next_cell": 2,
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "For this question, you need to program a representation transfer case to reuse an existing network. A network *ResNet-18* previously trained on the natural image set *ImageNet* is used as the source model. This network has been pre-trained on a different dataset, but of the same nature, i.e. for object recognition. The adaptation of the original network for the new task is done by replacing the head of the network (output layer) so that the network can run on the [*Lego Brick*](https://www.kaggle.com/joosthazelzet/lego-brick-images) dataset, separated into a set of [training](https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-train.zip) and [test](https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/lego-test.zip) (warning: 190 MB overall, the files are directly available on PAX). You should be able to achieve very good performance on this game in just one training epoch.\n",
        "\n",
        "In short, you need to modify the last fully connected layer of the neural network (the `fc` layer) to fit the number of classes in the dataset (16 classes here). In addition, you need to freeze the other layers of the *ResNet-18* network before the new fully connected output layer. Also write the line of code needed to infer the network in the `forward` method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "673cae3a",
      "metadata": {
        "editable": false,
        "id": "673cae3a",
        "lang": "fr"
      },
      "source": [
        "## Q2A\n",
        "Changez la dernière couche pleinement connectée du réseau de neurones (couche `fc`) afin de l'adapter au nombre de classes du jeu de données (16 classes ici). De plus, gelez les autres couches du réseau *ResNet-18* se trouvant avant la nouvelle couche pleinement connectée de sortie. Écrivez également la ligne de code nécessaire à l'inférence du réseau dans la méthode `forward`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7269ff60",
      "metadata": {
        "editable": false,
        "id": "7269ff60",
        "lang": "en"
      },
      "source": [
        "## Q2A\n",
        "Change the last fully connected layer of the neural network (the `fc` layer) to fit the number of classes in the dataset (16 classes here). In addition, freeze the other layers of the *ResNet-18* network before the new fully connected output layer. Also write the line of code needed to infer the network in the `forward` method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2984840b",
      "metadata": {
        "editable": false,
        "id": "2984840b",
        "lang": "fr"
      },
      "source": [
        "### Entrez votre solution à Q2A dans la cellule ci-dessous"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "342622c5",
      "metadata": {
        "editable": false,
        "id": "342622c5",
        "lang": "en"
      },
      "source": [
        "### Enter your answer to Q2A in the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05daf452",
      "metadata": {
        "editable": false,
        "tags": [
          "feedback"
        ],
        "id": "05daf452"
      },
      "source": [
        "<div class=\"feedback-cell\" style=\"background: rgba(100 , 100 , 100 , 0.4)\">\n",
        "                <h3>Votre soumission a été enregistrée!</h3>\n",
        "                <ul>\n",
        "                    <li>notez qu'il n'y a <strong>pas</strong> de correction automatique pour cet exercice&puncsp;;</li>\n",
        "                    <li>par conséquent, votre note est <strong>actuellement</strong> zéro&puncsp;;</li>\n",
        "                    <li>elle sera cependant ajustée par le professeur dès que la correction manuelle sera complétée&puncsp;;</li>\n",
        "                    <li>vous pouvez soumettre autant de fois que nécessaire jusqu'à la date d'échéance&puncsp;;</li>\n",
        "                    <li>mais évitez de soumettre inutilement.</li>\n",
        "                </ul>\n",
        "            </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57f6592",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-22T22:28:00.255072Z",
          "start_time": "2022-12-22T22:28:00.240750Z"
        },
        "deletable": false,
        "id": "d57f6592",
        "tags": [
          "user-answer-D4Q2A",
          "editable"
        ]
      },
      "outputs": [],
      "source": [
        "class LegoNet(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Crée le réseau de neurone pré-entraîné\n",
        "        # Create the pretrained neural network\n",
        "        self.model = resnet18(pretrained=pretrained, progress=False)\n",
        "\n",
        "        # Récupère le nombre de neurones avant la couche de classement\n",
        "        # Get the number of features before the classification layer\n",
        "        dim_before_fc = self.model.fc.in_features\n",
        "\n",
        "\n",
        "        # *** TODO ***\n",
        "        # Changer la dernière couche pleinement connecté pour avoir le bon\n",
        "        # nombre de neurones de sortie\n",
        "        # Change the last fully connected layer to have the right\n",
        "        # number of output neurons\n",
        "        # ******\n",
        "        self.model.fc = nn.Linear(dim_before_fc, 16)\n",
        "\n",
        "        if pretrained:\n",
        "            # *** TODO ***\n",
        "            # Geler les paramètres qui ne font pas partie de la dernière couche fc\n",
        "            # Conseil: utiliser l'itérateur named_parameters() et la variable requires_grad\n",
        "            # Freeze parameters that are not part of the last fc layer\n",
        "            # Tip: use named_parameters() iterator and requires_grad variable\n",
        "            for name, param in self.model.named_parameters():\n",
        "                if name != 'fc.weight' and name != 'fc.bias':\n",
        "                    param.requires_grad = False\n",
        "            # ******\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # *** TODO ***\n",
        "        # Appeler la fonction forward du réseau préentraîné (resnet18) de LegoNet\n",
        "        # Call the forward function of the pre-trained network (resnet18) of LegoNet\n",
        "        return self.model(x)\n",
        "        # ******"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dbf4fc",
      "metadata": {
        "editable": false,
        "id": "b6dbf4fc",
        "lang": "fr",
        "tags": []
      },
      "source": [
        "### Patron de code réponse à l'exercice Q2A"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a198f208",
      "metadata": {
        "editable": false,
        "id": "a198f208",
        "lang": "en",
        "tags": []
      },
      "source": [
        "### Q2A answer code template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0010ed0",
      "metadata": {
        "editable": false,
        "id": "d0010ed0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class LegoNet(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Crée le réseau de neurone pré-entraîné\n",
        "        # Create the pretrained neural network\n",
        "        self.model = resnet18(pretrained=pretrained, progress=False)\n",
        "\n",
        "        # Récupère le nombre de neurones avant la couche de classement\n",
        "        # Get the number of features before the classification layer\n",
        "        dim_before_fc = self.model.fc.in_features\n",
        "\n",
        "\n",
        "        # *** TODO ***\n",
        "        # Changer la dernière couche pleinement connecté pour avoir le bon\n",
        "        # nombre de neurones de sortie\n",
        "        # Change the last fully connected layer to have the right\n",
        "        # number of output neurons\n",
        "        # ******\n",
        "\n",
        "        if pretrained:\n",
        "            # *** TODO ***\n",
        "            # Geler les paramètres qui ne font pas partie de la dernière couche fc\n",
        "            # Conseil: utiliser l'itérateur named_parameters() et la variable requires_grad\n",
        "            # Freeze parameters that are not part of the last fc layer\n",
        "            # Tip: use named_parameters() iterator and requires_grad variable\n",
        "            pass # Retirer le pass / remove the pass\n",
        "            # ******\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # *** TODO ***\n",
        "        # Appeler la fonction forward du réseau préentraîné (resnet18) de LegoNet\n",
        "        # Call the forward function of the pre-trained network (resnet18) of LegoNet\n",
        "        return false\n",
        "        # ******"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62375b7e",
      "metadata": {
        "editable": false,
        "id": "62375b7e",
        "lang": "fr"
      },
      "source": [
        "## Q2B\n",
        "Écrivez les lignes de code manquantes pour la préparation de l'entraînement et celles à l'intérieur de la boucle d'entraînement selon deux modes:\n",
        "1. Entraîner le réseau en exécutant le code **sans** préentraînement, le réseau devrait être entraîné en moins de 30 minutes sur CPU (et quelques minutes sur GPU).\n",
        "2. Entraîner le réseau en exécutant le code **avec** préentraînement (*fine tuning*)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43ae9be",
      "metadata": {
        "editable": false,
        "id": "b43ae9be",
        "lang": "en"
      },
      "source": [
        "## Q2B\n",
        "Write the missing lines of code for the training preparation and those inside the training loop in two modes:\n",
        "1. Train the network by running the code **without** pre-training, the network should be trained in less than 30 minutes on CPU (and a few minutes on GPU).\n",
        "2. Train the network by running the code **with** pre-training (*fine tuning*)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b08e2bf",
      "metadata": {
        "editable": false,
        "id": "8b08e2bf",
        "lang": "fr"
      },
      "source": [
        "### Entrez votre solution à Q2B dans la cellule ci-dessous"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14da637b",
      "metadata": {
        "editable": false,
        "id": "14da637b",
        "lang": "en"
      },
      "source": [
        "### Enter your answer to Q2B in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "822868b0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-22T22:48:36.696349Z",
          "start_time": "2022-12-22T22:47:55.256107Z"
        },
        "deletable": false,
        "id": "822868b0",
        "tags": [
          "user-answer-D4Q2B",
          "editable"
        ],
        "outputId": "93705307-a622-4cb2-a32f-8e139d8a7281"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 1/1:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:   1%|          | 1/100 [00:00<00:14,  6.64it/s]\u001b[A\n",
            "Epoch 1/1:   2%|▏         | 2/100 [00:00<00:14,  6.82it/s]\u001b[A\n",
            "Epoch 1/1:   3%|▎         | 3/100 [00:00<00:14,  6.86it/s]\u001b[A\n",
            "Epoch 1/1:   4%|▍         | 4/100 [00:00<00:14,  6.71it/s]\u001b[A\n",
            "Epoch 1/1:   5%|▌         | 5/100 [00:00<00:13,  6.80it/s]\u001b[A\n",
            "Epoch 1/1:   6%|▌         | 6/100 [00:00<00:13,  6.83it/s]\u001b[A\n",
            "Epoch 1/1:   7%|▋         | 7/100 [00:01<00:13,  6.90it/s]\u001b[A\n",
            "Epoch 1/1:   8%|▊         | 8/100 [00:01<00:13,  6.96it/s]\u001b[A\n",
            "Epoch 1/1:   9%|▉         | 9/100 [00:01<00:13,  6.98it/s]\u001b[A\n",
            "Epoch 1/1:  10%|█         | 10/100 [00:01<00:12,  7.01it/s]\u001b[A\n",
            "Epoch 1/1:  11%|█         | 11/100 [00:01<00:12,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  12%|█▏        | 12/100 [00:01<00:12,  7.01it/s]\u001b[A\n",
            "Epoch 1/1:  13%|█▎        | 13/100 [00:01<00:12,  6.81it/s]\u001b[A\n",
            "Epoch 1/1:  14%|█▍        | 14/100 [00:02<00:12,  6.88it/s]\u001b[A\n",
            "Epoch 1/1:  15%|█▌        | 15/100 [00:02<00:12,  6.95it/s]\u001b[A\n",
            "Epoch 1/1:  16%|█▌        | 16/100 [00:02<00:12,  6.98it/s]\u001b[A\n",
            "Epoch 1/1:  17%|█▋        | 17/100 [00:02<00:11,  6.97it/s]\u001b[A\n",
            "Epoch 1/1:  18%|█▊        | 18/100 [00:02<00:11,  6.99it/s]\u001b[A\n",
            "Epoch 1/1:  19%|█▉        | 19/100 [00:02<00:11,  7.01it/s]\u001b[A\n",
            "Epoch 1/1:  20%|██        | 20/100 [00:02<00:11,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  21%|██        | 21/100 [00:03<00:11,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  22%|██▏       | 22/100 [00:03<00:11,  7.06it/s]\u001b[A\n",
            "Epoch 1/1:  23%|██▎       | 23/100 [00:03<00:10,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  24%|██▍       | 24/100 [00:03<00:10,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  25%|██▌       | 25/100 [00:03<00:10,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  26%|██▌       | 26/100 [00:03<00:10,  7.00it/s]\u001b[A\n",
            "Epoch 1/1:  27%|██▋       | 27/100 [00:03<00:10,  6.98it/s]\u001b[A\n",
            "Epoch 1/1:  28%|██▊       | 28/100 [00:04<00:10,  7.00it/s]\u001b[A\n",
            "Epoch 1/1:  29%|██▉       | 29/100 [00:04<00:10,  7.00it/s]\u001b[A\n",
            "Epoch 1/1:  30%|███       | 30/100 [00:04<00:09,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  31%|███       | 31/100 [00:04<00:09,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  32%|███▏      | 32/100 [00:04<00:09,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  33%|███▎      | 33/100 [00:04<00:09,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  34%|███▍      | 34/100 [00:04<00:09,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  35%|███▌      | 35/100 [00:05<00:09,  7.05it/s]\u001b[A\n",
            "Epoch 1/1:  36%|███▌      | 36/100 [00:05<00:09,  7.07it/s]\u001b[A\n",
            "Epoch 1/1:  37%|███▋      | 37/100 [00:05<00:08,  7.06it/s]\u001b[A\n",
            "Epoch 1/1:  38%|███▊      | 38/100 [00:05<00:08,  7.05it/s]\u001b[A\n",
            "Epoch 1/1:  39%|███▉      | 39/100 [00:05<00:08,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  40%|████      | 40/100 [00:05<00:08,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  41%|████      | 41/100 [00:05<00:08,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  42%|████▏     | 42/100 [00:06<00:08,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  43%|████▎     | 43/100 [00:06<00:08,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  44%|████▍     | 44/100 [00:06<00:08,  6.99it/s]\u001b[A\n",
            "Epoch 1/1:  45%|████▌     | 45/100 [00:06<00:07,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  46%|████▌     | 46/100 [00:06<00:07,  7.05it/s]\u001b[A\n",
            "Epoch 1/1:  47%|████▋     | 47/100 [00:06<00:07,  7.06it/s]\u001b[A\n",
            "Epoch 1/1:  48%|████▊     | 48/100 [00:06<00:07,  7.05it/s]\u001b[A\n",
            "Epoch 1/1:  49%|████▉     | 49/100 [00:07<00:07,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  50%|█████     | 50/100 [00:07<00:07,  7.06it/s]\u001b[A\n",
            "Epoch 1/1:  51%|█████     | 51/100 [00:07<00:06,  7.08it/s]\u001b[A\n",
            "Epoch 1/1:  52%|█████▏    | 52/100 [00:07<00:06,  7.09it/s]\u001b[A\n",
            "Epoch 1/1:  53%|█████▎    | 53/100 [00:07<00:06,  7.08it/s]\u001b[A\n",
            "Epoch 1/1:  54%|█████▍    | 54/100 [00:07<00:06,  7.06it/s]\u001b[A\n",
            "Epoch 1/1:  55%|█████▌    | 55/100 [00:07<00:06,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  56%|█████▌    | 56/100 [00:08<00:06,  7.01it/s]\u001b[A\n",
            "Epoch 1/1:  57%|█████▋    | 57/100 [00:08<00:06,  7.01it/s]\u001b[A\n",
            "Epoch 1/1:  58%|█████▊    | 58/100 [00:08<00:05,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  59%|█████▉    | 59/100 [00:08<00:05,  7.00it/s]\u001b[A\n",
            "Epoch 1/1:  60%|██████    | 60/100 [00:08<00:05,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  61%|██████    | 61/100 [00:08<00:05,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  62%|██████▏   | 62/100 [00:08<00:05,  7.05it/s]\u001b[A\n",
            "Epoch 1/1:  63%|██████▎   | 63/100 [00:08<00:05,  7.06it/s]\u001b[A\n",
            "Epoch 1/1:  64%|██████▍   | 64/100 [00:09<00:05,  7.05it/s]\u001b[A\n",
            "Epoch 1/1:  65%|██████▌   | 65/100 [00:09<00:04,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  66%|██████▌   | 66/100 [00:09<00:04,  7.03it/s]\u001b[A\n",
            "Epoch 1/1:  67%|██████▋   | 67/100 [00:09<00:04,  7.00it/s]\u001b[A\n",
            "Epoch 1/1:  68%|██████▊   | 68/100 [00:09<00:04,  7.01it/s]\u001b[A\n",
            "Epoch 1/1:  69%|██████▉   | 69/100 [00:09<00:04,  7.02it/s]\u001b[A\n",
            "Epoch 1/1:  70%|███████   | 70/100 [00:09<00:04,  7.04it/s]\u001b[A\n",
            "Epoch 1/1:  71%|███████   | 71/100 [00:10<00:04,  6.89it/s]\u001b[A\n",
            "Epoch 1/1:  72%|███████▏  | 72/100 [00:10<00:04,  6.84it/s]\u001b[A\n",
            "Epoch 1/1:  73%|███████▎  | 73/100 [00:10<00:03,  6.87it/s]\u001b[A\n",
            "Epoch 1/1:  74%|███████▍  | 74/100 [00:10<00:03,  6.91it/s]\u001b[A\n",
            "Epoch 1/1:  75%|███████▌  | 75/100 [00:10<00:03,  6.93it/s]\u001b[A\n",
            "Epoch 1/1:  76%|███████▌  | 76/100 [00:10<00:03,  6.89it/s]\u001b[A\n",
            "Epoch 1/1:  77%|███████▋  | 77/100 [00:11<00:03,  6.92it/s]\u001b[A\n",
            "Epoch 1/1:  78%|███████▊  | 78/100 [00:11<00:03,  6.90it/s]\u001b[A\n",
            "Epoch 1/1:  79%|███████▉  | 79/100 [00:11<00:03,  6.70it/s]\u001b[A\n",
            "Epoch 1/1:  80%|████████  | 80/100 [00:11<00:02,  6.74it/s]\u001b[A\n",
            "Epoch 1/1:  81%|████████  | 81/100 [00:11<00:02,  6.79it/s]\u001b[A\n",
            "Epoch 1/1:  82%|████████▏ | 82/100 [00:11<00:02,  6.81it/s]\u001b[A\n",
            "Epoch 1/1:  83%|████████▎ | 83/100 [00:11<00:02,  6.83it/s]\u001b[A\n",
            "Epoch 1/1:  84%|████████▍ | 84/100 [00:12<00:02,  6.85it/s]\u001b[A\n",
            "Epoch 1/1:  85%|████████▌ | 85/100 [00:12<00:02,  6.86it/s]\u001b[A\n",
            "Epoch 1/1:  86%|████████▌ | 86/100 [00:12<00:02,  6.88it/s]\u001b[A\n",
            "Epoch 1/1:  87%|████████▋ | 87/100 [00:12<00:01,  6.91it/s]\u001b[A\n",
            "Epoch 1/1:  88%|████████▊ | 88/100 [00:12<00:01,  6.96it/s]\u001b[A\n",
            "Epoch 1/1:  89%|████████▉ | 89/100 [00:12<00:01,  6.99it/s]\u001b[A\n",
            "Epoch 1/1:  90%|█████████ | 90/100 [00:12<00:01,  6.98it/s]\u001b[A\n",
            "Epoch 1/1:  91%|█████████ | 91/100 [00:13<00:01,  6.79it/s]\u001b[A\n",
            "Epoch 1/1:  92%|█████████▏| 92/100 [00:13<00:01,  6.77it/s]\u001b[A\n",
            "Epoch 1/1:  93%|█████████▎| 93/100 [00:13<00:01,  6.74it/s]\u001b[A\n",
            "Epoch 1/1:  94%|█████████▍| 94/100 [00:13<00:00,  6.79it/s]\u001b[A\n",
            "Epoch 1/1:  95%|█████████▌| 95/100 [00:13<00:00,  6.88it/s]\u001b[A\n",
            "Epoch 1/1:  96%|█████████▌| 96/100 [00:13<00:00,  6.91it/s]\u001b[A\n",
            "Epoch 1/1:  97%|█████████▋| 97/100 [00:13<00:00,  6.99it/s]\u001b[A\n",
            "Epoch 1/1:  98%|█████████▊| 98/100 [00:14<00:00,  7.00it/s]\u001b[A\n",
            "Epoch 1/1:  99%|█████████▉| 99/100 [00:14<00:00,  7.00it/s]\u001b[A\n",
            "Epoch 1/1: 100%|██████████| 100/100 [00:14<00:00,  6.98it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:14<00:00, 14.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [-] pretrained test acc. 82.103611%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 1/1:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1/1:   1%|          | 1/100 [00:00<00:23,  4.16it/s]\u001b[A\n",
            "Epoch 1/1:   2%|▏         | 2/100 [00:00<00:23,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:   3%|▎         | 3/100 [00:00<00:23,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:   4%|▍         | 4/100 [00:00<00:22,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:   5%|▌         | 5/100 [00:01<00:22,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:   6%|▌         | 6/100 [00:01<00:22,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:   7%|▋         | 7/100 [00:01<00:22,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:   8%|▊         | 8/100 [00:01<00:22,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:   9%|▉         | 9/100 [00:02<00:21,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  10%|█         | 10/100 [00:02<00:21,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  11%|█         | 11/100 [00:02<00:21,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  12%|█▏        | 12/100 [00:02<00:21,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  13%|█▎        | 13/100 [00:03<00:20,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  14%|█▍        | 14/100 [00:03<00:20,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  15%|█▌        | 15/100 [00:03<00:20,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  16%|█▌        | 16/100 [00:03<00:20,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  17%|█▋        | 17/100 [00:04<00:19,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  18%|█▊        | 18/100 [00:04<00:19,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  19%|█▉        | 19/100 [00:04<00:19,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  20%|██        | 20/100 [00:04<00:19,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  21%|██        | 21/100 [00:05<00:18,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  22%|██▏       | 22/100 [00:05<00:18,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  23%|██▎       | 23/100 [00:05<00:18,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  24%|██▍       | 24/100 [00:05<00:18,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  25%|██▌       | 25/100 [00:05<00:17,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  26%|██▌       | 26/100 [00:06<00:17,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  27%|██▋       | 27/100 [00:06<00:17,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  28%|██▊       | 28/100 [00:06<00:17,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  29%|██▉       | 29/100 [00:06<00:16,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  30%|███       | 30/100 [00:07<00:16,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  31%|███       | 31/100 [00:07<00:16,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  32%|███▏      | 32/100 [00:07<00:16,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  33%|███▎      | 33/100 [00:07<00:15,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  34%|███▍      | 34/100 [00:08<00:15,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  35%|███▌      | 35/100 [00:08<00:15,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  36%|███▌      | 36/100 [00:08<00:15,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  37%|███▋      | 37/100 [00:08<00:15,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  38%|███▊      | 38/100 [00:09<00:14,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  39%|███▉      | 39/100 [00:09<00:14,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  40%|████      | 40/100 [00:09<00:14,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  41%|████      | 41/100 [00:09<00:14,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  42%|████▏     | 42/100 [00:10<00:13,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  43%|████▎     | 43/100 [00:10<00:13,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  44%|████▍     | 44/100 [00:10<00:13,  4.20it/s]\u001b[A\n",
            "Epoch 1/1:  45%|████▌     | 45/100 [00:10<00:13,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  46%|████▌     | 46/100 [00:11<00:12,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  47%|████▋     | 47/100 [00:11<00:12,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  48%|████▊     | 48/100 [00:11<00:12,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  49%|████▉     | 49/100 [00:11<00:12,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  50%|█████     | 50/100 [00:11<00:11,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  51%|█████     | 51/100 [00:12<00:11,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  52%|█████▏    | 52/100 [00:12<00:11,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  53%|█████▎    | 53/100 [00:12<00:11,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  54%|█████▍    | 54/100 [00:12<00:11,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  55%|█████▌    | 55/100 [00:13<00:10,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  56%|█████▌    | 56/100 [00:13<00:10,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  57%|█████▋    | 57/100 [00:13<00:10,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  58%|█████▊    | 58/100 [00:13<00:10,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  59%|█████▉    | 59/100 [00:14<00:09,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  60%|██████    | 60/100 [00:14<00:09,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  61%|██████    | 61/100 [00:14<00:09,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  62%|██████▏   | 62/100 [00:14<00:09,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  63%|██████▎   | 63/100 [00:15<00:08,  4.14it/s]\u001b[A\n",
            "Epoch 1/1:  64%|██████▍   | 64/100 [00:15<00:08,  4.16it/s]\u001b[A\n",
            "Epoch 1/1:  65%|██████▌   | 65/100 [00:15<00:08,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  66%|██████▌   | 66/100 [00:15<00:08,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  67%|██████▋   | 67/100 [00:16<00:07,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  68%|██████▊   | 68/100 [00:16<00:07,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  69%|██████▉   | 69/100 [00:16<00:07,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  70%|███████   | 70/100 [00:16<00:07,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  71%|███████   | 71/100 [00:16<00:06,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  72%|███████▏  | 72/100 [00:17<00:06,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  73%|███████▎  | 73/100 [00:17<00:06,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  74%|███████▍  | 74/100 [00:17<00:06,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  75%|███████▌  | 75/100 [00:17<00:05,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  76%|███████▌  | 76/100 [00:18<00:05,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  77%|███████▋  | 77/100 [00:18<00:05,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  78%|███████▊  | 78/100 [00:18<00:05,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  79%|███████▉  | 79/100 [00:18<00:05,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  80%|████████  | 80/100 [00:19<00:04,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  81%|████████  | 81/100 [00:19<00:04,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  82%|████████▏ | 82/100 [00:19<00:04,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  83%|████████▎ | 83/100 [00:19<00:04,  4.20it/s]\u001b[A\n",
            "Epoch 1/1:  84%|████████▍ | 84/100 [00:20<00:03,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  85%|████████▌ | 85/100 [00:20<00:03,  4.20it/s]\u001b[A\n",
            "Epoch 1/1:  86%|████████▌ | 86/100 [00:20<00:03,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  87%|████████▋ | 87/100 [00:20<00:03,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  88%|████████▊ | 88/100 [00:21<00:02,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  89%|████████▉ | 89/100 [00:21<00:02,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  90%|█████████ | 90/100 [00:21<00:02,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  91%|█████████ | 91/100 [00:21<00:02,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  92%|█████████▏| 92/100 [00:22<00:01,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  93%|█████████▎| 93/100 [00:22<00:01,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  94%|█████████▍| 94/100 [00:22<00:01,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  95%|█████████▌| 95/100 [00:22<00:01,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  96%|█████████▌| 96/100 [00:22<00:00,  4.18it/s]\u001b[A\n",
            "Epoch 1/1:  97%|█████████▋| 97/100 [00:23<00:00,  4.17it/s]\u001b[A\n",
            "Epoch 1/1:  98%|█████████▊| 98/100 [00:23<00:00,  4.19it/s]\u001b[A\n",
            "Epoch 1/1:  99%|█████████▉| 99/100 [00:23<00:00,  4.20it/s]\u001b[A\n",
            "Epoch 1/1: 100%|██████████| 100/100 [00:23<00:00,  4.19it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:23<00:00, 23.86s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [-] not pretrained test acc. 45.054945%\n"
          ]
        }
      ],
      "source": [
        "def train(pretrained):\n",
        "\n",
        "    # Définit les paramètres d'entraînement\n",
        "    # Nous vous conseillons ces paramètres, mais vous pouvez les changer\n",
        "    # Defines the training parameters\n",
        "    # We recommend these settings, but you can change them\n",
        "    nb_epoch = 1\n",
        "    learning_rate = 0.01\n",
        "    momentum = 0.9\n",
        "    batch_size = 64\n",
        "\n",
        "    # Définit les transformations nécessaires pour le chargement du jeu de données\n",
        "    # Defines the transformations needed to load the dataset\n",
        "    totensor = T.ToTensor()\n",
        "    normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "    composition = T.Compose([totensor, normalize])\n",
        "\n",
        "    # Charge le dataset d'entraînement\n",
        "    # Load the training dataset\n",
        "    train_set = ImageFolder('/pax/shared/GIF-4101-7005/lego-train', transform=composition)\n",
        "\n",
        "    # Selectionne 10% du jeu de test aléatoirement pour alléger le calcul\n",
        "    # Select 10% of the test set randomly to simplify the calculation\n",
        "    test_set = ImageFolder('/pax/shared/GIF-4101-7005/lego-test', transform=composition)\n",
        "    idx = numpy.random.randint(0, len(test_set), int(0.1 * len(test_set)))\n",
        "    test_set.samples = [test_set.samples[i] for i in idx]\n",
        "\n",
        "    # *** TODO ***\n",
        "    # Créer les dataloader PyTorch avec la classe DataLoader\n",
        "    # Create PyTorch dataloaders with the DataLoader class\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Instancier un réseau LegoNet dans une variable nommée \"model\"\n",
        "    # Instantiate a LegoNet network in a variable named \"model\n",
        "    # ******\n",
        "    model = LegoNet(pretrained)\n",
        "\n",
        "    # Place le réseau au bon endroit, variable DEVICE définit si cuda est utilisé ou non\n",
        "    # Places the network in the right place, variable DEVICE defines if cuda is used or not\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # *** TODO ***\n",
        "    # Instancier une fonction d'erreur CrossEntropyLoss et\n",
        "    # la mettre dans une variable nommée criterion\n",
        "    # Instantiate a CrossEntropyLoss error function and\n",
        "    # put it in a variable named criterion\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Instancier l'algorithme d'optimisation SGD\n",
        "    # Conseil: Filtrez les paramètres non-gelés!\n",
        "    # Ne pas oublier de lui donner les hyperparamètres d'entraînement :\n",
        "    # learning rate et momentum!\n",
        "    # Instantiate the SGD optimization algorithm\n",
        "    # Tip: Filter out unfrozen parameters!\n",
        "    # Don't forget to give it the training hyperparameters :\n",
        "    # learning rate and momentum!\n",
        "    params = list(filter(lambda x: x.requires_grad, model.parameters()))\n",
        "    optimizer = torch.optim.SGD(params, lr=learning_rate, momentum=momentum)\n",
        "\n",
        "    # Mettre le réseau en mode entraînement\n",
        "    # Set the network in training mode\n",
        "    # ******\n",
        "    model.train()\n",
        "\n",
        "    # Récupère le nombre total de batch pour une époque\n",
        "    # Retrieves the total number of batches for an epoch.\n",
        "    total_batch = len(train_loader)\n",
        "\n",
        "    for i_epoch in tqdm(range(nb_epoch)):\n",
        "        progress_dataloader = tqdm(train_loader, desc=\"Epoch {}/{}\".format(i_epoch+1, nb_epoch))\n",
        "        progress_dataloader.set_description(\"Epoch {}/{}\".format(i_epoch+1, nb_epoch))\n",
        "\n",
        "        train_losses = []\n",
        "        for batch in progress_dataloader:\n",
        "            images, targets = batch\n",
        "\n",
        "            images = images.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "\n",
        "            # *** TODO ***\n",
        "            # Mettre les gradients à zéro\n",
        "            # Set gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Calculer:\n",
        "            # 1. l'inférence dans une variable \"predictions\"\n",
        "            # 2. l'erreur dans une variable \"loss\"\n",
        "            # Compute:\n",
        "            # 1. the inference in a \"predictions\" variable\n",
        "            # 2. the error in a \"loss\" variable\n",
        "            predictions = model.forward(images)\n",
        "            loss = criterion(predictions, targets)\n",
        "\n",
        "            # Rétropropager l'erreur et effectuer une étape d'optimisation\n",
        "            # Backpropagate the error and perform an optimization step\n",
        "            # ******\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Ajoute le loss de la batch\n",
        "            # Adds the batch loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "    # Affiche le score à l'écran\n",
        "    # Display score\n",
        "    test_acc = compute_accuracy(model, test_loader, DEVICE)\n",
        "    if pretrained:\n",
        "        print(' [-] pretrained test acc. {:.6f}%'.format(test_acc * 100))\n",
        "    else:\n",
        "        print(' [-] not pretrained test acc. {:.6f}%'.format(test_acc * 100))\n",
        "\n",
        "    # Libère la cache sur le GPU : *Important sur un cluster de GPU*\n",
        "    # Free the cache on the GPU: *Important on a GPU cluster*\n",
        "    torch.cuda.empty_cache()\n",
        "train(True)\n",
        "train(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf24610",
      "metadata": {
        "editable": false,
        "id": "edf24610",
        "lang": "fr",
        "tags": []
      },
      "source": [
        "### Patron de code réponse à l'exercice Q2B"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e7d2a5a",
      "metadata": {
        "editable": false,
        "id": "8e7d2a5a",
        "lang": "en",
        "tags": []
      },
      "source": [
        "### Q2B answer code template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80261809",
      "metadata": {
        "editable": false,
        "id": "80261809"
      },
      "outputs": [],
      "source": [
        "def train(pretrained):\n",
        "\n",
        "    # Définit les paramètres d'entraînement\n",
        "    # Nous vous conseillons ces paramètres, mais vous pouvez les changer\n",
        "    # Defines the training parameters\n",
        "    # We recommend these settings, but you can change them\n",
        "    nb_epoch = 1\n",
        "    learning_rate = 0.01\n",
        "    momentum = 0.9\n",
        "    batch_size = 64\n",
        "\n",
        "    # Définit les transformations nécessaires pour le chargement du jeu de données\n",
        "    # Defines the transformations needed to load the dataset\n",
        "    totensor = T.ToTensor()\n",
        "    normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                            std=[0.229, 0.224, 0.225])\n",
        "    composition = T.Compose([totensor, normalize])\n",
        "\n",
        "    # Charge le dataset d'entraînement\n",
        "    # Load the training dataset\n",
        "    train_set = ImageFolder('/pax/shared/GIF-4101-7005/lego-train', transform=composition)\n",
        "\n",
        "    # Selectionne 10% du jeu de test aléatoirement pour alléger le calcul\n",
        "    # Select 10% of the test set randomly to simplify the calculation\n",
        "    test_set = ImageFolder('/pax/shared/GIF-4101-7005/lego-test', transform=composition)\n",
        "    idx = numpy.random.randint(0, len(test_set), int(0.1 * len(test_set)))\n",
        "    test_set.samples = [test_set.samples[i] for i in idx]\n",
        "\n",
        "    # *** TODO ***\n",
        "    # Créer les dataloader PyTorch avec la classe DataLoader\n",
        "    # Create PyTorch dataloaders with the DataLoader class\n",
        "\n",
        "    # Instancier un réseau LegoNet dans une variable nommée \"model\"\n",
        "    # Instantiate a LegoNet network in a variable named \"model\n",
        "    # ******\n",
        "\n",
        "    # Place le réseau au bon endroit, variable DEVICE définit si cuda est utilisé ou non\n",
        "    # Places the network in the right place, variable DEVICE defines if cuda is used or not\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # *** TODO ***\n",
        "    # Instancier une fonction d'erreur CrossEntropyLoss et\n",
        "    # la mettre dans une variable nommée criterion\n",
        "    # Instantiate a CrossEntropyLoss error function and\n",
        "    # put it in a variable named criterion\n",
        "\n",
        "    # Instancier l'algorithme d'optimisation SGD\n",
        "    # Conseil: Filtrez les paramètres non-gelés!\n",
        "    # Ne pas oublier de lui donner les hyperparamètres d'entraînement :\n",
        "    # learning rate et momentum!\n",
        "    # Instantiate the SGD optimization algorithm\n",
        "    # Tip: Filter out unfrozen parameters!\n",
        "    # Don't forget to give it the training hyperparameters :\n",
        "    # learning rate and momentum!\n",
        "\n",
        "    # Mettre le réseau en mode entraînement\n",
        "    # Set the network in training mode\n",
        "    # ******\n",
        "\n",
        "    # Récupère le nombre total de batch pour une époque\n",
        "    # Retrieves the total number of batches for an epoch.\n",
        "    total_batch = len(train_loader)\n",
        "\n",
        "    for i_epoch in tqdm(range(nb_epoch)):\n",
        "        progress_dataloader = tqdm(train_loader, desc=\"Epoch {}/{}\".format(i_epoch+1, nb_epoch))\n",
        "        progress_dataloader.set_description(\"Epoch {}/{}\".format(i_epoch+1, nb_epoch))\n",
        "\n",
        "        train_losses = []\n",
        "        for batch in progress_dataloader:\n",
        "            images, targets = batch\n",
        "\n",
        "            images = images.to(DEVICE)\n",
        "            targets = targets.to(DEVICE)\n",
        "\n",
        "            # *** TODO ***\n",
        "            # Mettre les gradients à zéro\n",
        "            # Set gradients to zero\n",
        "\n",
        "            # Calculer:\n",
        "            # 1. l'inférence dans une variable \"predictions\"\n",
        "            # 2. l'erreur dans une variable \"loss\"\n",
        "            # Compute:\n",
        "            # 1. the inference in a \"predictions\" variable\n",
        "            # 2. the error in a \"loss\" variable\n",
        "\n",
        "            # Rétropropager l'erreur et effectuer une étape d'optimisation\n",
        "            # Backpropagate the error and perform an optimization step\n",
        "            # ******\n",
        "\n",
        "            # Ajoute le loss de la batch\n",
        "            # Adds the batch loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "    # Affiche le score à l'écran\n",
        "    # Display score\n",
        "    test_acc = compute_accuracy(model, test_loader, DEVICE)\n",
        "    if pretrained:\n",
        "        print(' [-] pretrained test acc. {:.6f}%'.format(test_acc * 100))\n",
        "    else:\n",
        "        print(' [-] not pretrained test acc. {:.6f}%'.format(test_acc * 100))\n",
        "\n",
        "   # Libère la cache sur le GPU : *Important sur un cluster de GPU*\n",
        "   # Free the cache on the GPU: *Important on a GPU cluster*\n",
        "   torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "PAX": {
      "userLang": "fr"
    },
    "celltoolbar": "",
    "jupytext": {
      "notebook_metadata_filter": "celltoolbar",
      "text_representation": {
        "extension": ".md",
        "format_name": "markdown",
        "format_version": "1.3",
        "jupytext_version": "1.13.6"
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (PAX)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "fr",
      "targetLang": "en",
      "useGoogleTranslate": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}