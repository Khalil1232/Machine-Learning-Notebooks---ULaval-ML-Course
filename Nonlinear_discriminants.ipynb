{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khalil1232/Machine-Learning-ULaval/blob/main/Nonlinear_discriminants.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c779b879",
      "metadata": {
        "editable": false,
        "id": "c779b879",
        "lang": "fr",
        "tags": [
          "problem-title"
        ]
      },
      "source": [
        "# Devoir 3, Question 2 : Discriminants non-linéaires"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96783490",
      "metadata": {
        "editable": false,
        "id": "96783490",
        "lang": "en",
        "tags": [
          "problem-title"
        ]
      },
      "source": [
        "# Homework 3, Question 2: Nonlinear discriminants"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41a9097",
      "metadata": {
        "editable": false,
        "id": "b41a9097",
        "lang": "fr",
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "## Code préambule"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77a37028",
      "metadata": {
        "editable": false,
        "id": "77a37028",
        "lang": "en",
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "## Preamble code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42739fa8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-14T17:03:27.645216Z",
          "start_time": "2022-12-14T17:03:27.631332Z"
        },
        "editable": false,
        "id": "42739fa8",
        "tags": [
          "problem-context",
          "autoexec"
        ]
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import time\n",
        "import pandas\n",
        "pandas.set_option('display.max_colwidth', 0)\n",
        "import collections\n",
        "import itertools\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Nous ne voulons pas être signalé par ce type d'avertissement, non pertinent pour le devoir\n",
        "# We don't want to be signaled of this warning, irrelevant for the homework\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Fonction pour vérifier le temps d'exécution\n",
        "# Function to verify execution time\n",
        "_times = []\n",
        "def checkTime(maxduration, question):\n",
        "    duration = _times[-1] - _times[-2]\n",
        "    if duration > maxduration:\n",
        "        print(\"[ATTENTION] Votre code pour la question {0} met trop de temps à s'exécuter! \".format(question)+\n",
        "              \"Le temps maximum permis est de {0:.4f} secondes, \".format(maxduration)+\n",
        "              \"mais votre code a requis {0:.4f} secondes! \".format(duration)+\n",
        "              \"Assurez-vous que vous ne faites pas d'appels bloquants (par exemple à show()) dans cette boucle!\")\n",
        "\n",
        "# Définition des durées d'exécution maximales pour chaque classifieur\n",
        "# Definition of maximum execution time for each classifier\n",
        "TMAX_KNN = 40\n",
        "TMAX_SVM = 200\n",
        "TMAX_MLP = 400\n",
        "TMAX_EVAL = 80"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b94195",
      "metadata": {
        "editable": false,
        "id": "c1b94195",
        "lang": "fr",
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "## Q2A\n",
        "Soit les classifieurs suivants, présentés en classe :\n",
        "- Classement par les $k$-plus proches voisins avec distance euclidienne (`neighbors.KNeighborsClassifier`);\n",
        "- Séparateurs à vastes marges avec noyau gaussien (`svm.SVC`), notez que le paramètre du noyau de la fonction est $\\gamma=\\frac{1}{2\\sigma^2}$;\n",
        "- Perceptron multicouche pour le classement (`neural_network.MLPClassifier`). Pour cette méthode, utilisez le paramètre `max_iter=100`.\n",
        "\n",
        "Pour les trois algorithmes présentés ci-haut, déterminez les hyperparamètres importants qui peuvent influencer significativement les résultats d’apprentissage (limitez-vous à un maximum de deux hyperparamètres importants par algorithme). Dans le tableau de réponse, affichez les deux hyperparamètres choisis. Donnez également la plage de valeurs qui devrait être testée pour chacun de ces hyperparamètres afin de faire un bon ajustement de la configuration des classifieurs sur le jeu Pendigits. Vous testerez ces plages dans un prochain exercice.\n",
        "\n",
        "Le jeu de données [Pendigits](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) vise à reconnaître des chiffres manuscrits (10 classes) à partir des coordonnées de 8 points des tracés des caractères (16 variables). Le jeu de données est [disponible directement sur PAX](https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/ucipendigits.npy)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42243991",
      "metadata": {
        "editable": false,
        "id": "42243991",
        "lang": "en",
        "tags": [
          "problem-statement"
        ]
      },
      "source": [
        "## Q2A\n",
        "Consider the following classifiers, presented in class:\n",
        "- Classification by $k$-nearest neighbors with Euclidean distance (`neighbors.KNeighborsClassifier`);\n",
        "- Support vector machine with Gaussian kernel (`svm.SVC`), note that the kernel parameter of the function is $\\gamma=\\frac{1}{2\\sigma^2}$;\n",
        "- Multilayer perceptron for classification (`neural_network.MLPClassifier`). For this method, use the parameter `max_iter = 100`.\n",
        "\n",
        "For the three algorithms presented above, determine the important hyperparameters that can significantly influence learning outcomes (limit yourself to a maximum of two important hyperparameters per algorithm). In the answer table, display the 2 chosen hyperparameters. Also give the range of values that should be tested for each of these hyperparameters in order to make a good fit for the configuration of the classifiers on the Pendigits game. You will test these ranges in a future exercise.\n",
        "\n",
        "The [Pendigits](https://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) dataset aims at recognizing handwritten digits (10 classes) from the coordinates of 8 points taken from the character plots (16 variables). The dataset is [available directly on PAX](https://pax.ulaval.ca/static/GIF-4101-7005/fichiers/ucipendigits.npy)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae984f7",
      "metadata": {
        "editable": false,
        "id": "8ae984f7",
        "lang": "fr",
        "tags": []
      },
      "source": [
        "### Entrez votre solution à Q2A dans la cellule ci-dessous\n",
        "Rapportez les paramètres d’entraînement et les plages de valeurs correspondantes que vous avez choisis pour chacun des algorithmes, en modifiant le tableau donné ci-dessous, dans la cellule de solution.\n",
        "~~~md\n",
        "Algorithme | Parametre 1    | Parametre 2    | Plage param. 1 |Plage param. 2 |\n",
        "-----------|----------------|----------------|----------------|---------------|\n",
        "KNN        | -              | -              | -              | -             |\n",
        "SVM        | -              | -              | -              | -             |\n",
        "MLP        | -              | -              | -              | -             |\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f5638b",
      "metadata": {
        "editable": false,
        "id": "69f5638b",
        "lang": "en",
        "tags": []
      },
      "source": [
        "### Enter your answer to Q2A in the cell below\n",
        "Report the training parameters and the corresponding ranges of values you have chosen for each of the algorithms, by modifying the table structure below into the solution cell.\n",
        "~~~md\n",
        "Algorithm  | Parameter 1    | Parameter 2    | Range param. 1 |Range param. 2 |\n",
        "-----------|----------------|----------------|----------------|---------------|\n",
        "KNN        | -              | -              | -              | -             |\n",
        "SVM        | -              | -              | -              | -             |\n",
        "MLP        | -              | -              | -              | -             |\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2d5f27",
      "metadata": {
        "editable": false,
        "tags": [
          "feedback"
        ],
        "id": "9c2d5f27"
      },
      "source": [
        "<div class=\"feedback-cell\" style=\"background: rgba(100 , 100 , 100 , 0.4)\">\n",
        "                <h3>Votre soumission a été enregistrée!</h3>\n",
        "                <ul>\n",
        "                    <li>notez qu'il n'y a <strong>pas</strong> de correction automatique pour cet exercice&puncsp;;</li>\n",
        "                    <li>par conséquent, votre note est <strong>actuellement</strong> zéro&puncsp;;</li>\n",
        "                    <li>elle sera cependant ajustée par le professeur dès que la correction manuelle sera complétée&puncsp;;</li>\n",
        "                    <li>vous pouvez soumettre autant de fois que nécessaire jusqu'à la date d'échéance&puncsp;;</li>\n",
        "                    <li>mais évitez de soumettre inutilement.</li>\n",
        "                </ul>\n",
        "            </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a742b45e",
      "metadata": {
        "deletable": false,
        "id": "a742b45e",
        "tags": [
          "user-answer-D3Q2A",
          "editable"
        ]
      },
      "source": [
        "Algorithme | Parametre 1            | Parametre 2         | Plage param. 1                 |Plage param. 2 |\n",
        "-----------|------------------------|---------------------|--------------------------------|\n",
        "  KNN      | -number of neighbors   | -weights            | - k=1----->55                |-['uniform','distance']     \n",
        "SVM        | -kernel                | -the penalty C      | - [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]  |[100, 10, 1.0, 0.1, 0.001]\n",
        "MLP        | -hidden layer sizes    | -activation function| - n=3---->100             |['identity','logistic','relu','tanh']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3a5a25",
      "metadata": {
        "editable": false,
        "id": "3e3a5a25",
        "lang": "fr",
        "tags": []
      },
      "source": [
        "## Q2B\n",
        "Tester les discriminants de la question Q2A avec le jeu de données Pendigits. Normalisez les données dans $[0,1]^D$ avant vos traitements (`preprocessing.minmax_scale`). Utilisez 5500 instances choisies au hasard comme données d’entraînement et les 5492 données restantes pour les tests. Notez que la dernière colonne du jeu de données correspond aux étiquettes de classe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd34f5b",
      "metadata": {
        "editable": false,
        "id": "9fd34f5b",
        "lang": "en",
        "tags": []
      },
      "source": [
        "## Q2B\n",
        "Test the discriminants of question Q2A with the Pendigits dataset. Normalize the data in $[0,1]^D$ before your processing (`preprocessing.minmax_scale`). Use 5500 randomly selected instances for training data and the remaining 5492 data for testing. Note that the last column of the dataset corresponds to the class labels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3175307",
      "metadata": {
        "editable": false,
        "id": "e3175307",
        "lang": "fr",
        "tags": []
      },
      "source": [
        "### Entrez votre solution à Q2B dans la cellule ci-dessous"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c3140f",
      "metadata": {
        "editable": false,
        "id": "f1c3140f",
        "lang": "en",
        "tags": []
      },
      "source": [
        "### Enter your answer to Q2B in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c75ba96",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-14T17:01:29.766236Z",
          "start_time": "2022-12-14T16:59:21.538017Z"
        },
        "deletable": false,
        "id": "4c75ba96",
        "tags": [
          "user-answer-D3Q2B",
          "editable"
        ],
        "outputId": "c2b42aa2-04ae-4f4e-8dce-34155278ea31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lecture du jeu de données Pendigits...\n",
            "Lecture terminé.\n",
            "En cours...\n",
            "fin KNeighborsClassifier\n",
            "fin SVM\n",
            "fin Perceptron multicouche\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifiers</th>\n",
              "      <th>Optimal_hp1</th>\n",
              "      <th>Optimal_hp2</th>\n",
              "      <th>Time_train</th>\n",
              "      <th>Time_test</th>\n",
              "      <th>Score_train</th>\n",
              "      <th>Score_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>2</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.524</td>\n",
              "      <td>0.995455</td>\n",
              "      <td>0.989803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC</td>\n",
              "      <td>rbf</td>\n",
              "      <td>10</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.187</td>\n",
              "      <td>0.998000</td>\n",
              "      <td>0.995448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>8</td>\n",
              "      <td>logistic</td>\n",
              "      <td>2.117</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.896000</td>\n",
              "      <td>0.887109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Classifiers Optimal_hp1 Optimal_hp2  Time_train  Time_test  \\\n",
              "0  KNeighborsClassifier  2           uniform     0.001       0.524       \n",
              "1  SVC                   rbf         10          0.111       0.187       \n",
              "2  MLPClassifier         8           logistic    2.117       0.002       \n",
              "\n",
              "   Score_train  Score_test  \n",
              "0  0.995455     0.989803    \n",
              "1  0.998000     0.995448    \n",
              "2  0.896000     0.887109    "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialisation du jeu de données Pendigits\n",
        "# Initializing Pendigits dataset\n",
        "print('Lecture du jeu de données Pendigits...')\n",
        "filePendigits = '/pax/shared/GIF-4101-7005/ucipendigits.npy'\n",
        "dataPendigits = numpy.load(filePendigits)\n",
        "data, target = dataPendigits[:, :-1].astype('float32'), dataPendigits[:, -1]\n",
        "print('Lecture terminé.')\n",
        "print('En cours...')\n",
        "# *** TODO ***\n",
        "# Normalisez les données d'entrée entre 0 et 1 pour toutes les dimensions.\n",
        "# Notez que la fonction retourne les données d'une manière différente des\n",
        "# fonctions load_* que vous avez déjà utilisées (ex. load_iris(),\n",
        "# load_breast_cancer()). Assurez-vous que vous utilisez correctement les\n",
        "# données et qu'elles sont du bon type!\n",
        "# Normalize the input data between 0 and 1 for all dimensions.\n",
        "# Note that the function returns the data in a different way than the load_*\n",
        "# functions you you have used before (e.g. load_iris(), load_breast_cancer()).\n",
        "# Make sure you are using the data correctly and that it is of the right type!\n",
        "y = target\n",
        "X = minmax_scale(data)\n",
        "\n",
        "# Séparez le jeu de données Pendigits en deux sous-jeux: entraînement (5500)\n",
        "# et test (reste des données). Pour la suite du code, rappelez-vous que vous ne\n",
        "# pouvez PAS vous servir du jeu de test pour déterminer la configuration\n",
        "# d'hyper-paramètres la plus performante. Ce jeu de test ne doit être utilisé qu'à\n",
        "# la toute fin, pour rapporter les résultats finaux en généralisation.\n",
        "# Split the Pendigits dataset into two subsets: training (5500) and testing\n",
        "# (the rest of the data). For the remainder of the code, remember that you\n",
        "# cannot use the test set to determine the most appropriate hyper-parameter\n",
        "# configuration. This test set should only be used at the very end, to report the\n",
        "# final results in generalization.\n",
        "# ******\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5500, test_size=len(y)-5500, random_state=0)\n",
        "# Création du tableau pour accumuler les résultats\n",
        "# Creation of the table to accumulate results\n",
        "results = {'Classifiers':[],\n",
        "           'Optimal_hp1':[],\n",
        "           'Optimal_hp2':[],\n",
        "           'Time_train':[],\n",
        "           'Time_test':[],\n",
        "           'Score_train':[],\n",
        "           'Score_test':[],\n",
        "          }\n",
        "\n",
        "_times.append(time.time())\n",
        "\n",
        "# Pour chaque classifieurs (k-PPV, SVM à noyau gaussien, Perceptron multicouche),\n",
        "# déterminez les valeurs optimales des hyperparamètres à utiliser. Suivez les\n",
        "# instructions de l'énoncé de Q2A et Q2B quant au nombre d'hyperparamètres à optimiser.\n",
        "# Vous êtes libres d'utiliser la méthodologie que vous souhaitez, en autant que\n",
        "# vous ne touchez pas au jeu de test pour l'optimisation.\n",
        "# For each classifier (k-NN, Gaussian kernel SVM, Multi-layer Perceptron),\n",
        "# determine the optimal values of the hyperparameters to use. Follow the\n",
        "# instructions in the statement of Q2A and Q2B regarding the number of\n",
        "# hyperparameters to optimize. You are free to use any methodology you wish, as\n",
        "# long as you do not make use of the test set for optimization.\n",
        "\n",
        "# -------\n",
        "# Optimisez la paramétrisation du k-PPV\n",
        "# Optimize k-NN parametrization\n",
        "\n",
        "# *** TODO ***\n",
        "# Ajustez les hyperparamètres du k-PPV\n",
        "# Adjust k-NN hyperparamters\n",
        "k_val = numpy.arange(1,55)\n",
        "weights = ['uniform', 'distance']\n",
        "scores = numpy.zeros((len(k_val), len(weights)))\n",
        "score_max = 0\n",
        "opt_k=0\n",
        "opt_w=0\n",
        "for i in k_val:\n",
        "    for j in weights:\n",
        "        score = 0\n",
        "        XX_train, XX_test, yy_train, yy_test = train_test_split(X_train, y_train, train_size=0.7, test_size=0.3, random_state=0)\n",
        "        clf_knn = KNeighborsClassifier(n_neighbors= i , weights= j)\n",
        "        clf_knn.fit(XX_train, yy_train)\n",
        "        score = clf_knn.score(XX_test, yy_test)\n",
        "        if score > score_max:\n",
        "            score_max = score\n",
        "            opt_k = i\n",
        "            opt_w = j\n",
        "\n",
        "# ******\n",
        "\n",
        "clf_name = clf_knn.__class__.__name__\n",
        "if clf_name not in results['Classifiers']:\n",
        "    results['Classifiers'].append(clf_name)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'entraînement pour le k-PPV\n",
        "# et mettez-le dans la variable time_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training time for the k-NN\n",
        "# and put it in the time_train variable by\n",
        "# replacing the 0.\n",
        "clf_knn = KNeighborsClassifier(n_neighbors= opt_k , weights= opt_w)\n",
        "t_deb = time.time()\n",
        "clf_knn.fit(X_train, y_train)\n",
        "duration = numpy.round_(time.time() - t_deb, 3)\n",
        "score = clf_knn.score(X_train, y_train)\n",
        "time_train = duration\n",
        "# ******\n",
        "\n",
        "results['Time_train'].append(time_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le score d'entraînement pour le k-PPV\n",
        "# et mettez-le dans la variable score_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training score for the k-NN\n",
        "# and put it in the score_train variable by\n",
        "# replacing the 0.\n",
        "score_train = score\n",
        "# ******\n",
        "\n",
        "results['Score_train'].append(score_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Stockez vos valeurs optimales\n",
        "# d'hyperparamètres dans les variables\n",
        "# optimal_hp1 et optimal_hp2 en remplaçant\n",
        "# le 0.\n",
        "# Store your optimal hyperparameters values\n",
        "# in the variables optimal_hp1 and optimal_hp2 by\n",
        "# replacing the 0.\n",
        "optimal_hp1 = opt_k\n",
        "optimal_hp2 = opt_w\n",
        "# ******\n",
        "\n",
        "results['Optimal_hp1'].append(optimal_hp1)\n",
        "results['Optimal_hp2'].append(optimal_hp2)\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_KNN, \"k-plus proches voisins\")\n",
        "print('fin KNeighborsClassifier')\n",
        "\n",
        "# -------\n",
        "\n",
        "# Optimisez la paramétrisation du SVM à noyau gaussien\n",
        "# Optimize Gaussian kernel SVM parametrization\n",
        "\n",
        "# *** TODO ***\n",
        "# Ajustez les hyperparamètres du SVM\n",
        "# Adjust SVM hyperparamters\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "C = [100, 10, 1.0, 0.1, 0.001]\n",
        "scores = numpy.zeros((len(kernels), len(C)))\n",
        "score_max = 0\n",
        "opt_ker='linear'\n",
        "opt_C=0\n",
        "for i in kernels:\n",
        "    for j in C:\n",
        "        score = 0\n",
        "        XX_train, XX_test, yy_train, yy_test = train_test_split(X_train, y_train, train_size=0.7, test_size=0.3, random_state=0)\n",
        "        clf_svc = SVC(kernel = i, C = j)\n",
        "        clf_svc.fit(XX_train, yy_train)\n",
        "        score = clf_svc.score(XX_test, yy_test)\n",
        "        if score > score_max:\n",
        "            score_max = score\n",
        "            opt_ker = i\n",
        "            opt_C = j\n",
        "\n",
        "\n",
        "# ******\n",
        "\n",
        "clf_name = clf_svc.__class__.__name__\n",
        "if clf_name not in results['Classifiers']:\n",
        "    results['Classifiers'].append(clf_name)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'entraînement pour le SVM\n",
        "# et mettez-le dans la variable time_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training time for the SVM\n",
        "# and put it in the time_train variable by\n",
        "# replacing the 0.\n",
        "clf_svc = SVC(kernel = opt_ker, C = opt_C)\n",
        "t_deb = time.time()\n",
        "clf_svc.fit(X_train, y_train)\n",
        "duration = numpy.round_(time.time() - t_deb, 3)\n",
        "score = clf_svc.score(X_train, y_train)\n",
        "time_train = duration\n",
        "\n",
        "# ******\n",
        "\n",
        "results['Time_train'].append(time_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le score d'entraînement pour le SVM\n",
        "# et mettez-le dans la variable score_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training score for the SVM\n",
        "# and put it in the score_train variable by\n",
        "# replacing the 0.\n",
        "score_train = score\n",
        "# ******\n",
        "\n",
        "results['Score_train'].append(score_train)\n",
        "# *** TODO ***\n",
        "# Stockez vos valeurs optimales\n",
        "# d'hyperparamètres dans les variables\n",
        "# optimal_hp1 et optimal_hp2 en remplaçant\n",
        "# le 0.\n",
        "# Store your optimal hyperparameters values\n",
        "# in the variables optimal_hp1 and optimal_hp2 by\n",
        "# replacing the 0.\n",
        "optimal_hp1 = opt_ker\n",
        "optimal_hp2 = opt_C\n",
        "# ******\n",
        "\n",
        "results['Optimal_hp1'].append(optimal_hp1)\n",
        "results['Optimal_hp2'].append(optimal_hp2)\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_SVM, \"Support vector machine\")\n",
        "print('fin SVM')\n",
        "\n",
        "# -------\n",
        "\n",
        "# Optimisez la paramétrisation du perceptron multicouche\n",
        "# Optimize multilayer perceptron parametrization\n",
        "\n",
        "# *** TODO ***\n",
        "# Ajustez les hyperparamètres du MLP\n",
        "# Adjust MLP hyperparamters\n",
        "neurons = numpy.arange(3,20)\n",
        "act_func = ['identity','logistic','relu','tanh']\n",
        "scores = numpy.zeros((len(neurons), len(act_func)))\n",
        "score_max = 0\n",
        "opt_size= 3\n",
        "opt_func= 'identity'\n",
        "for i in neurons:\n",
        "    for j in act_func:\n",
        "        score = 0\n",
        "        XX_train, XX_test, yy_train, yy_test = train_test_split(X_train, y_train, train_size=0.7, test_size=0.3, random_state=0)\n",
        "        clf_mlp = MLPClassifier(hidden_layer_sizes = opt_size, activation = opt_func)\n",
        "        clf_mlp.fit(XX_train, yy_train)\n",
        "        score = clf_mlp.score(XX_test, yy_test)\n",
        "        if score > score_max:\n",
        "            score_max = score\n",
        "            opt_size = i\n",
        "            opt_func = j\n",
        "\n",
        "\n",
        "# ******\n",
        "\n",
        "clf_name = clf_mlp.__class__.__name__\n",
        "if clf_name not in results['Classifiers']:\n",
        "    results['Classifiers'].append(clf_name)\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'entraînement pour le PMC\n",
        "# et mettez-le dans la variable time_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training time for the MLP\n",
        "# and put it in the time_train variable by\n",
        "# replacing the 0.\n",
        "clf_mlp = MLPClassifier(hidden_layer_sizes = opt_size, activation = opt_func)\n",
        "t_deb = time.time()\n",
        "clf_mlp.fit(X_train, y_train)\n",
        "duration = numpy.round_(time.time() - t_deb, 3)\n",
        "score = clf_mlp.score(X_train, y_train)\n",
        "time_train = duration\n",
        "\n",
        "# ******\n",
        "\n",
        "results['Time_train'].append(time_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le score d'entraînement pour le PMC\n",
        "# et mettez-le dans la variable score_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training score for the MLP\n",
        "# and put it in the score_train variable by\n",
        "# replacing the 0.\n",
        "score_train = score\n",
        "# ******\n",
        "\n",
        "results['Score_train'].append(score_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Stockez vos valeurs optimales\n",
        "# d'hyperparamètres dans les variables\n",
        "# optimal_hp1 et optimal_hp2 en remplaçant\n",
        "# le 0.\n",
        "# Store your optimal hyperparameters values\n",
        "# in the variables optimal_hp1 and optimal_hp2 by\n",
        "# replacing the 0.\n",
        "optimal_hp1 = opt_size\n",
        "optimal_hp2 = opt_func\n",
        "# ******\n",
        "\n",
        "results['Optimal_hp1'].append(optimal_hp1)\n",
        "results['Optimal_hp2'].append(optimal_hp2)\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_MLP, \"Perceptron multicouche\")\n",
        "print('fin Perceptron multicouche')\n",
        "\n",
        "# -------\n",
        "\n",
        "# Après avoir bien recherché les meilleures paramétrisations\n",
        "# pour vos discriminants, évaluez leurs performances sur le\n",
        "# jeu de test. Rapportez les performances dans le tableau généré.\n",
        "\n",
        "# k-PPV / k-NN\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'inference pour le k-PPV\n",
        "# et mettez-le dans la variable time_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the inference time for the k-NN\n",
        "# and put it in the time_test variable by\n",
        "# replacing the 0.\n",
        "\n",
        "t_deb = time.time()\n",
        "score = clf_knn.score(X_test, y_test)\n",
        "duration = numpy.round_(time.time() - t_deb, 3)\n",
        "\n",
        "time_test = duration\n",
        "\n",
        "\n",
        "# Calculez le score en test pour le k-PPV\n",
        "# et mettez-le dans la variable score_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the test score for the k-NN\n",
        "# and put it in the score_test variable by\n",
        "# replacing the 0.\n",
        "score_test = score\n",
        "# ******\n",
        "\n",
        "results['Time_test'].append(time_test)\n",
        "results['Score_test'].append(score_test)\n",
        "\n",
        "# SVM\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'inference pour le SVM\n",
        "# et mettez-le dans la variable time_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the inference time for the SVM\n",
        "# and put it in the time_test variable by\n",
        "# replacing the 0.\n",
        "t_deb = time.time()\n",
        "score = clf_svc.score(X_test, y_test)\n",
        "duration = numpy.round_(time.time() - t_deb, 3)\n",
        "\n",
        "time_test = duration\n",
        "\n",
        "# Calculez le score en test pour le SVM\n",
        "# et mettez-le dans la variable score_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the test score for the SVM\n",
        "# and put it in the score_test variable by\n",
        "# replacing the 0.\n",
        "score_test = score\n",
        "# ******\n",
        "\n",
        "results['Time_test'].append(time_test)\n",
        "results['Score_test'].append(score_test)\n",
        "# PMC / MLP\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'inference pour le PMC\n",
        "# et mettez-le dans la variable time_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the inference time for the MLP\n",
        "# and put it in the time_test variable by\n",
        "# replacing the 0.\n",
        "t_deb = time.time()\n",
        "score = clf_mlp.score(X_test, y_test)\n",
        "duration = numpy.round_(time.time() - t_deb, 3)\n",
        "\n",
        "time_test = duration\n",
        "\n",
        "# Calculez le score en test pour le PMC\n",
        "# et mettez-le dans la variable score_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the test score for the MLP\n",
        "# and put it in the score_test variable by\n",
        "# replacing the 0.\n",
        "score_test = score\n",
        "# ******\n",
        "\n",
        "results['Time_test'].append(time_test)\n",
        "results['Score_test'].append(score_test)\n",
        "\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_EVAL, \"Evaluation des modèles\")\n",
        "\n",
        "# Affichage des résultats\n",
        "# Display results\n",
        "df = pandas.DataFrame(results)\n",
        "display.display(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac947730",
      "metadata": {
        "editable": false,
        "id": "ac947730",
        "lang": "fr",
        "tags": []
      },
      "source": [
        "### Patron de code réponse à l'exercice Q2B"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de44382",
      "metadata": {
        "editable": false,
        "id": "6de44382",
        "lang": "en",
        "tags": []
      },
      "source": [
        "### Q2B answer code template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0ec534d",
      "metadata": {
        "editable": false,
        "id": "a0ec534d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Initialisation du jeu de données Pendigits\n",
        "# Initializing Pendigits dataset\n",
        "print('Lecture du jeu de données Pendigits...')\n",
        "filePendigits = '/pax/shared/GIF-4101-7005/ucipendigits.npy'\n",
        "dataPendigits = numpy.load(filePendigits)\n",
        "data, target = dataPendigits[:, :-1].astype('float32'), dataPendigits[:, -1]\n",
        "print('Lecture terminé.')\n",
        "\n",
        "# *** TODO ***\n",
        "# Normalisez les données d'entrée entre 0 et 1 pour toutes les dimensions.\n",
        "# Notez que les données sont retournées d'une manière différente des\n",
        "# fonctions load_* que vous avez déjà utilisées (ex. load_iris(),\n",
        "# load_breast_cancer()). Assurez-vous que vous utilisez correctement les\n",
        "# données et qu'elles sont du bon type!\n",
        "# Normalize the input data between 0 and 1 for all dimensions.\n",
        "# Note that that the data are provided in a different way than the load_*\n",
        "# functions you you have used before (e.g. load_iris(), load_breast_cancer()).\n",
        "# Make sure you are using the data correctly and that it is of the right type!\n",
        "\n",
        "# Séparez le jeu de données Pendigits en deux sous-jeux: entraînement (5500)\n",
        "# et test (reste des données). Pour la suite du code, rappelez-vous que vous ne\n",
        "# pouvez PAS vous servir du jeu de test pour déterminer la configuration\n",
        "# d'hyper-paramètres la plus performante. Ce jeu de test ne doit être utilisé qu'à\n",
        "# la toute fin, pour rapporter les résultats finaux en généralisation.\n",
        "# Split the Pendigits dataset into two subsets: training (5500) and testing\n",
        "# (the rest of the data). For the remainder of the code, remember that you\n",
        "# cannot use the test set to determine the most appropriate hyper-parameter\n",
        "# configuration. This test set should only be used at the very end, to report the\n",
        "# final results in generalization.\n",
        "# ******\n",
        "\n",
        "# Création du tableau pour accumuler les résultats\n",
        "# Creation of the table to accumulate results\n",
        "results = {'Classifiers':[],\n",
        "           'Optimal_hp1':[],\n",
        "           'Optimal_hp2':[],\n",
        "           'Time_train':[],\n",
        "           'Time_test':[],\n",
        "           'Score_train':[],\n",
        "           'Score_test':[],\n",
        "          }\n",
        "\n",
        "_times.append(time.time())\n",
        "\n",
        "# Pour chaque classifieurs (k-PPV, SVM à noyau gaussien, Perceptron multicouche),\n",
        "# déterminez les valeurs optimales des hyperparamètres à utiliser. Suivez les\n",
        "# instructions de l'énoncé de Q2A et Q2B quant au nombre d'hyperparamètres à optimiser.\n",
        "# Vous êtes libres d'utiliser la méthodologie que vous souhaitez, en autant que\n",
        "# vous ne touchez pas au jeu de test pour l'optimisation.\n",
        "# For each classifier (k-NN, Gaussian kernel SVM, Multi-layer Perceptron),\n",
        "# determine the optimal values of the hyperparameters to use. Follow the\n",
        "# instructions in the statement of Q2A and Q2B regarding the number of\n",
        "# hyperparameters to optimize. You are free to use any methodology you wish, as\n",
        "# long as you do not make use of the test set for optimization.\n",
        "\n",
        "# -------\n",
        "\n",
        "# Optimisez la paramétrisation du k-PPV\n",
        "# Optimize k-NN parametrization\n",
        "\n",
        "# *** TODO ***\n",
        "# Ajustez les hyperparamètres du k-PPV\n",
        "# Adjust k-NN hyperparamters\n",
        "clf_knn = KNeighborsClassifier()\n",
        "# ******\n",
        "\n",
        "clf_name = clf_knn.__class__.__name__\n",
        "if clf_name not in results['Classifiers']:\n",
        "    results['Classifiers'].append(clf_name)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'entraînement pour le k-PPV\n",
        "# et mettez-le dans la variable time_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training time for the k-NN\n",
        "# and put it in the time_train variable by\n",
        "# replacing the 0.\n",
        "time_train = 0\n",
        "# ******\n",
        "\n",
        "results['Time_train'].append(time_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le score d'entraînement pour le k-PPV\n",
        "# et mettez-le dans la variable score_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training score for the k-NN\n",
        "# and put it in the score_train variable by\n",
        "# replacing the 0.\n",
        "score_train = 0\n",
        "# ******\n",
        "\n",
        "results['Score_train'].append(score_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Stockez vos valeurs optimales\n",
        "# d'hyperparamètres dans les variables\n",
        "# optimal_hp1 et optimal_hp2 en remplaçant\n",
        "# le 0.\n",
        "# Store your optimal hyperparameters values\n",
        "# in the variables optimal_hp1 and optimal_hp2 by\n",
        "# replacing the 0.\n",
        "optimal_hp1 = 0\n",
        "optimal_hp2 = 0\n",
        "# ******\n",
        "\n",
        "results['Optimal_hp1'].append(optimal_hp1)\n",
        "results['Optimal_hp2'].append(optimal_hp2)\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_KNN, \"k-plus proches voisins\")\n",
        "\n",
        "# -------\n",
        "\n",
        "# Optimisez la paramétrisation du SVM à noyau gaussien\n",
        "# Optimize Gaussian kernel SVM parametrization\n",
        "\n",
        "# *** TODO ***\n",
        "# Ajustez les hyperparamètres du SVM\n",
        "# Adjust SVM hyperparamters\n",
        "clf_svc = SVC()\n",
        "# ******\n",
        "\n",
        "clf_name = clf_svc.__class__.__name__\n",
        "if clf_name not in results['Classifiers']:\n",
        "    results['Classifiers'].append(clf_name)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'entraînement pour le SVM\n",
        "# et mettez-le dans la variable time_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training time for the SVM\n",
        "# and put it in the time_train variable by\n",
        "# replacing the 0.\n",
        "time_train = 0\n",
        "# ******\n",
        "\n",
        "results['Time_train'].append(time_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le score d'entraînement pour le SVM\n",
        "# et mettez-le dans la variable score_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training score for the SVM\n",
        "# and put it in the score_train variable by\n",
        "# replacing the 0.\n",
        "score_train = 0\n",
        "# ******\n",
        "\n",
        "results['Score_train'].append(score_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Stockez vos valeurs optimales\n",
        "# d'hyperparamètres dans les variables\n",
        "# optimal_hp1 et optimal_hp2 en remplaçant\n",
        "# le 0.\n",
        "# Store your optimal hyperparameters values\n",
        "# in the variables optimal_hp1 and optimal_hp2 by\n",
        "# replacing the 0.\n",
        "optimal_hp1 = 0\n",
        "optimal_hp2 = 0\n",
        "# ******\n",
        "\n",
        "results['Optimal_hp1'].append(optimal_hp1)\n",
        "results['Optimal_hp2'].append(optimal_hp2)\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_SVM, \"Support vector machine\")\n",
        "\n",
        "# -------\n",
        "\n",
        "# Optimisez la paramétrisation du perceptron multicouche\n",
        "# Optimize multilayer perceptron parametrization\n",
        "\n",
        "# *** TODO ***\n",
        "# Ajustez les hyperparamètres du MLP\n",
        "# Adjust MLP hyperparamters\n",
        "clf_mlp = MLPClassifier()\n",
        "# ******\n",
        "\n",
        "clf_name = clf_mlp.__class__.__name__\n",
        "if clf_name not in results['Classifiers']:\n",
        "    results['Classifiers'].append(clf_name)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'entraînement pour le PMC\n",
        "# et mettez-le dans la variable time_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training time for the MLP\n",
        "# and put it in the time_train variable by\n",
        "# replacing the 0.\n",
        "time_train = 0\n",
        "# ******\n",
        "\n",
        "results['Time_train'].append(time_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le score d'entraînement pour le PMC\n",
        "# et mettez-le dans la variable score_train en\n",
        "# remplaçant le 0.\n",
        "# Calculate the training score for the MLP\n",
        "# and put it in the score_train variable by\n",
        "# replacing the 0.\n",
        "score_train = 0\n",
        "# ******\n",
        "\n",
        "results['Score_train'].append(score_train)\n",
        "\n",
        "# *** TODO ***\n",
        "# Stockez vos valeurs optimales\n",
        "# d'hyperparamètres dans les variables\n",
        "# optimal_hp1 et optimal_hp2 en remplaçant\n",
        "# le 0.\n",
        "# Store your optimal hyperparameters values\n",
        "# in the variables optimal_hp1 and optimal_hp2 by\n",
        "# replacing the 0.\n",
        "optimal_hp1 = 0\n",
        "optimal_hp2 = 0\n",
        "# ******\n",
        "\n",
        "results['Optimal_hp1'].append(optimal_hp1)\n",
        "results['Optimal_hp2'].append(optimal_hp2)\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_MLP, \"Perceptron multicouche\")\n",
        "\n",
        "# -------\n",
        "\n",
        "# Après avoir bien recherché les meilleures paramétrisations\n",
        "# pour vos discriminants, évaluez leurs performances sur le\n",
        "# jeu de test. Rapportez les performances dans le tableau généré.\n",
        "\n",
        "# k-PPV / k-NN\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'inference pour le k-PPV\n",
        "# et mettez-le dans la variable time_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the inference time for the k-NN\n",
        "# and put it in the time_test variable by\n",
        "# replacing the 0.\n",
        "time_test = 0\n",
        "\n",
        "# Calculez le score en test pour le k-PPV\n",
        "# et mettez-le dans la variable score_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the test score for the k-NN\n",
        "# and put it in the score_test variable by\n",
        "# replacing the 0.\n",
        "score_test = 0\n",
        "# ******\n",
        "\n",
        "results['Time_test'].append(time_test)\n",
        "results['Score_test'].append(score_test)\n",
        "\n",
        "# SVM\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'inference pour le SVM\n",
        "# et mettez-le dans la variable time_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the inference time for the SVM\n",
        "# and put it in the time_test variable by\n",
        "# replacing the 0.\n",
        "time_test = 0\n",
        "\n",
        "# Calculez le score en test pour le SVM\n",
        "# et mettez-le dans la variable score_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the test score for the SVM\n",
        "# and put it in the score_test variable by\n",
        "# replacing the 0.\n",
        "score_test = 0\n",
        "# ******\n",
        "\n",
        "results['Time_test'].append(time_test)\n",
        "results['Score_test'].append(score_test)\n",
        "\n",
        "# PMC / MLP\n",
        "\n",
        "# *** TODO ***\n",
        "# Calculez le temps d'inference pour le PMC\n",
        "# et mettez-le dans la variable time_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the inference time for the MLP\n",
        "# and put it in the time_test variable by\n",
        "# replacing the 0.\n",
        "time_test = 0\n",
        "\n",
        "# Calculez le score en test pour le PMC\n",
        "# et mettez-le dans la variable score_test en\n",
        "# remplaçant le 0.\n",
        "# Calculate the test score for the MLP\n",
        "# and put it in the score_test variable by\n",
        "# replacing the 0.\n",
        "score_test = 0\n",
        "# ******\n",
        "\n",
        "results['Time_test'].append(time_test)\n",
        "results['Score_test'].append(score_test)\n",
        "\n",
        "_times.append(time.time())\n",
        "checkTime(TMAX_EVAL, \"Evaluation des modèles\")\n",
        "\n",
        "# Affichage des résultats\n",
        "# Display results\n",
        "df = pandas.DataFrame(results)\n",
        "display.display(df)"
      ]
    }
  ],
  "metadata": {
    "PAX": {
      "userLang": "fr"
    },
    "celltoolbar": "",
    "jupytext": {
      "notebook_metadata_filter": "celltoolbar",
      "text_representation": {
        "extension": ".md",
        "format_name": "markdown",
        "format_version": "1.3",
        "jupytext_version": "1.13.6"
      }
    },
    "kernelspec": {
      "display_name": "Python 3 (PAX)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "fr",
      "targetLang": "en",
      "useGoogleTranslate": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}